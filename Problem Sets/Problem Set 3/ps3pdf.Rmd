---
title: "Problem Set 3"
author: "Ningyuan Wang"
date: "11/8/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(datasets)
library(dplyr)
library(tidyr)
library(data.table)
```

## Question 1

The question relates to estmiate the uncertainty of a statistical estimator using resampling methods (i.e. jackknife and bootstrap procedures). In this part, I wrote two functions to compute confidence itnervals using above methods, and then applied the functions to a small dataset.


a.
Write a function to compute jackknife confidence interval for theta = E(X) / E(Y), where x and y are two numeric vectors.
```{r}
jk_ci_vec= function(x,y, alpha = 0.05){
  ## the function serves to estimate confidence interval of  E(X) / E(Y) with 
  ## jackknife standard error method.
  ## input: two numeric vectors: x and y
  ## output: a confidence interval with jackknife method 
  
  x_bar = (sum(x) - x)/ (length(x) - 1) # mean of x dropping ith term
  y_bar = (sum(y)-y) / (length(y) - 1) # mean of y dropping ith term
  theta = c(x_bar / mean(y) , mean(x) / y_bar) 
  #combine x_bar / y_bar with dropping one term either in x or y

  theta_bar = mean(theta) #compute the estimate of theta
  
  se = sqrt((length(theta)-1)/length(theta) * sum((theta - theta_bar)^2)) #compute se
  
  lwr = theta_bar - qnorm(1-alpha/2) * se 
  upr = theta_bar + qnorm(1-alpha/2) * se #compute confidence bound
  c('2.5%' = lwr, '97.5%' =upr) # the function returns to the confident interval
}  
```


b. 
Write a fucntion to compute bootstrap confidence intervals for the same statistic of interest of numeric vectors x and y. The specific three bootstrap methods are percentile, basic bootstrap and normal approximation with bootstrap standard error.
```{r}
boot_ci_vec = function(x, y, n_boot = 1e3, alpha = 0.05) {
  ## The function serves to estmiate the confdience inteval of  E(X) / E(Y) with
  ## with three bootstrap methods.
  ## Input: two numeric vectors x and y
  ## Output: three confidence intervals of  E(X) / E(Y)  with the methods of 
  ## percentile, basic bootstrap and normal approximation, seperately.
  
  # bootsstrap resamples for x
  mat_x = sample(x, n_boot * length(x), replace = TRUE)
  dim(mat_x) = c(n_boot, length(x)) # each row is a dataset
  
  # bootsstrap resample for y
  mat_y = sample(y, n_boot * length(y), replace = TRUE)
  dim(mat_y) = c(n_boot, length(y)) # each row is a dataset
  
  # bootsrap estimates
  est = rowMeans(mat_x) / rowMeans(mat_y) 
  dim(est) = c(n_boot, 1) # each row is an estmiate
  est_hat = mean(est) # center of bootstrap distribution
  
  # sd of bootstrap
  sd_boot = sqrt(sum((est - est_hat)^2) / (length(est) - 1)) 
  
  # construct ci
  percent_ci = quantile(est, c(alpha/2, 1-alpha/2)) 
  boot_ci = c(lwr = 2 * est_hat - unname(percent_ci[2]), 
              upr = 2 * est_hat - unname(percent_ci[1] ))
  norm_ci = c(lwr = est_hat - qnorm(1-alpha/2)  * sd_boot, 
              upr = est_hat + qnorm(1-alpha/2)  * sd_boot)
  
  return(rbind(percent_ci, boot_ci, norm_ci))
}

```


c.
Apply above functions to the dataset ToothGrowth. Provide point estimates and confidence intervals for the ratio comparing mean odontoblast length for two supplements on each level of dose. 

```{r}
# compute the point estimate
point_est = ToothGrowth %>%
  pivot_wider(names_from = supp, values_from = len, 
              values_fn = list(len = mean)) %>%
  transmute(dose = dose, ratio = OJ / VC) # point estimate of ratio for each dose, 3 in total
```

```{r, echo = FALSE}
oj0.5 = ToothGrowth %>%
  filter(dose == 0.5 & supp == "OJ") %>%
  select(dose, len) %>%
  pull(len) #n=10

oj1 = ToothGrowth %>%
  filter(dose == 1.0 & supp == "OJ") %>%
  select(dose, len) %>%
  pull(len) #n=10

oj2 = ToothGrowth %>%
  filter(dose == 2.0 & supp == "OJ") %>%
  select(dose, len) %>%
  pull(len) #n=10

vc0.5 = ToothGrowth %>%
  filter(dose == 0.5 & supp == "VC") %>%
  select(dose, len) %>%
  pull(len) #n=10

vc1 = ToothGrowth %>%
  filter(dose == 1.0 & supp == "VC") %>%
  select(dose, len) %>%
  pull(len) #n=10

vc2 = ToothGrowth %>%
  filter(dose == 2.0 & supp == "VC") %>%
  select(dose, len) %>%
  pull(len) #n=10

# compute CI : 
# dose = 0.5
jk_ci_0.5 = jk_ci_vec(x = oj0.5, y = vc0.5)
boot_ci_0.5 = boot_ci_vec(x = oj0.5, y = vc0.5) 
tb0.5 = rbind(jk_ci_0.5,boot_ci_0.5 )

# dose = 1
jk_ci_1 = jk_ci_vec(x = oj1, y = vc1)
boot_ci_1 = boot_ci_vec(x = oj1, y = vc1) 
tb1 = rbind(jk_ci_1,boot_ci_1 )

# dose = 2
jk_ci_2 = jk_ci_vec(x = oj2, y = vc2)
boot_ci_2 = boot_ci_vec(x = oj2, y = vc2) 
tb2 = rbind(jk_ci_2,boot_ci_2 )



```

```{r, echo=FALSE}
## table output 
cap = 
  '*Confidence Intervals for Odontoblasts Length Estimate on Levels of Dose *'

data.table( Dose = rep(c(0.5, 1.0, 2.0), each = 4), 
            Estimate =rep(point_est$ratio, each = 4),
            'CI Method' = rep(c("Jackknife", "Percentile", "Bootstrap", 
                           "Normal"), 
                         times = 3),
            rbind(tb0.5, tb1, tb2)) %>% 
  knitr::kable(align = "r", digits = 3, caption = cap)
```



## Question 2

a. Write a function to compute jackknife confidence interval for theta = E(X) / E(Y), where x and y are two numeric matrices representing Monte Carlo replicates 

```{r}
jk_ci = function(x, y, alpha = 0.05){
  ## the function serves to estimate the CI with jackknife standard error
  ## input: two numerix matrices: x, y, each rowrepresenting a Monte Carlo 
  ## replicate.
  ## output: confidence intervals of theta = E(x) / E(y) with jackknife se
  ## for each replicate.
  
  # compute mean of x and y seperately with ith dropping, row by row
  x_bar = matrix( data = (rowSums(xmat) - xmat) / (ncol(xmat) - 1 ), 
                 nrow = nrow(xmat), ncol = ncol(xmat)) # each row is a dataset
  
  y_bar = matrix( data = (rowSums(ymat) - ymat) / (ncol(ymat) - 1 ), 
                  nrow = nrow(ymat), ncol = ncol(ymat)) # each row is a dataset
                   
  
  # compute theta = E(x) / E(y) with ith dropping
  theta = cbind(x_bar / rowMeans(ymat), rowMeans(xmat) / y_bar)
  
  theta_bar = rowMeans(theta) #compute theta_bar for each row

  #compute se and ci
  se = sqrt( (ncol(theta) - 1) / ncol(theta) * rowSums( (theta - theta_bar)^2 ) )
  l = theta_bar - qnorm(1-alpha/2) * se
  u = theta_bar + qnorm(1-alpha/2) * se
  cbind('2.5%' = l, '97.5%' =u) # the function returns to the confident intervals 
}
```


b. 
Write a fucntion to compute bootstrap confidence intervals for the same statistic of interest with numeric matrices x and y. The specific three bootstrap methods are percentile, basic bootstrap and normal approximation with bootstrap standard error.
```{r}
boot_ci = function(xmat, ymat, n_boot = 10, alpha = 0.05){
  ## the function serves to estimate the CI with three bootstrap methods
  ## input: two numerix matrices: xmat, ymat representing Monte Carlo replicates in every row
  ## output: three methods of CI for each Monte Carlo replicate (each row is a replicate)
  
  # bootstrap resampling for x and y separately
  x_boot = apply(xmat, MARGIN = 1, FUN = sample, size = ncol(xmat) * n_boot, replace =TRUE) 
  dim(x_boot) = c(ncol(xmat), n_boot, rep) # sample * bootsrap * rep
  x_est = colMeans(x_boot, dims = 1) # estimate on each combination of bootstrap and replicate
  
  
  y_boot = apply(ymat, MARGIN = 1, FUN = sample, size = ncol(ymat) * n_boot, replace =TRUE) 
  dim(y_boot) = c( ncol(ymat), n_boot, rep)
  y_est = colMeans(y_boot, dims = 1) 
  
  est = x_est / y_est # bootstrap *  replicate estimations, each column is a replicate
  est_hat = colMeans(est) # est_hat for each Monte Carlo replicate, each column is a replicate
  
  # quantiles 
  q = apply(est, MARGIN = 2, FUN = quantile, probs =  c(alpha/2, 1 - alpha/2) ) # quantile for bootstrap distribution
  # each column is  a replicate
  
  # sd for each replicate
  sd_boot = sqrt(colSums((est - est_hat) ^2) / (nrow(est) - 1)) 
  
  # construct ci for each replicate
  percent_ci = t(q) 
  boot_ci = cbind(lwr = 2 * est_hat - q[2, ], upr = 2 * est_hat - q[1, ]) 
  norm_ci = cbind(lwr = est_hat - qnorm(1-alpha/2) * sd_boot, upr = est_hat + qnorm(1-alpha/2) * sd_boot)
  out = cbind( percent_ci, boot_ci,  norm_ci) # combine three types of confidence intervals
  colnames(out) = c("percentile_lwr", "percentile_upr", "basicboot_lwr", "basicboot_upr", "normaprox_lwr", "normaprox_upr" )
  out
}
```


c.
Choose distributions for generating x and y samples. Then, carry out a Monte Carlo study to estimate and comparing following quantities for each type of confidence interval defined above. 

I choose Possion as distributions to sample X and Y: X ~ Pois(10), and Y ~ Pois(20). The sample size of X and Y is both 50, and Monte Carlo replicate size is 1000.
```{r}
# generate Monte Carlo replicates for X and Y, each row is a replicate dataset
size = 50 # the size of X and Y 
rep = 1e3 # Monte Carlo replicate size
xmat = rpois( n = size * rep, lambda = 10 )
dim(xmat) = c(rep, size) # rep * size

ymat = rpois(n = size * rep, lambda = 20)
dim(ymat) = c(rep, size) # rep * size

```


These are confidence intervals for partial Monte Carlo replicates after calling above functions.
```{r, echo=FALSE}
# compute the CI by calling above functions
jk = jk_ci(xmat, ymat) 
bt = boot_ci(xmat, ymat) 
cis = matrix(data = cbind(jk, bt), ncol = 8)
colnames(cis) = c("jk_lwr", "jk_upr", "pt_lwr", "pt_upr", "boot_lwr", "boot_upr",
               "norm_lwr", "norm_upr")


tb = data.table::data.table(cbind(jk, bt)) %>%
  knitr::kable(align = 'r', digits =3, 
             col.names= c("jk_lwr", "jk_upr", "pt_lwr", "pt_upr", "boot_lwr", "boot_upr",
               "norm_lwr", "norm_upr"))

             
head(tb, 10)
```


Coverage Probability 
```{r, echo = FALSE}
point_est = mean(xmat) / mean(ymat) 
true = 10 / 20 # lambda(X) / lambda(Y)

jk_prob = cis %>%
  as_tibble() %>%
  select(jk_lwr, jk_upr) %>%
  filter(true >= jk_lwr & true<= jk_upr) %>%
  summarize(jk_prob = n() / rep)


pt_prob = cis %>%
  as_tibble() %>%
  select(pt_lwr, pt_upr) %>%
  filter(true >= pt_lwr & true<= pt_upr) %>%
  summarize(pt_prob = n() / rep)

boot_prob = cis %>%
  as_tibble() %>%
  select(boot_lwr, boot_upr) %>%
  filter(true >= boot_lwr & true<= boot_upr) %>%
  summarize(boot_prob = n() / rep)

norm_prob = cis %>%
  as_tibble() %>%
  select(norm_lwr, norm_upr) %>%
  filter(true >= norm_lwr & true<= norm_upr) %>%
  summarize(norm_prob = n() / rep)
cap3 = '*Coverge Probability for Four Types of CI Method *'
data.table::data.table(jk_prob, pt_prob, boot_prob, norm_prob)%>%
  knitr::kable(align = "r", digits = 3, caption = cap3,
               col.names = c("Jackknife", "Percentile", "Bootstrap", "Normal"))
```

Average Length of CIs
```{r, echo=FALSE}
jk_len = mean(cis[,2] - cis[,1])
pt_len = mean(cis[,4] - cis[,3]) 
boot_len = mean(cis[,6] - cis[,5]) 
norm_len = mean(cis[,8] - cis[,7]) 

cap3 = '*Average Length for Four Types of CI Method *'
data.table::data.table(jk_len, pt_len, boot_len, norm_len)%>%
  knitr::kable(align = "r", digits = 3, caption = cap3,
               col.names = c("Jackknife", "Percentile", "Bootstrap", "Normal"))
```

Average Shape of CIs
```{r, echo=FALSE}
jk_shape = mean((cis[,2] - point_est) / (point_est - cis[,1])) 
pt_shape = mean((cis[,4] - point_est) / (point_est - cis[,3])) 
boot_shape = mean((cis[,6] - point_est) / (point_est - cis[,5])) 
norm_shape = mean((cis[,8] - point_est) / (point_est - cis[,7])) 

cap4 = '*Average Shape for Four Types of CI Method *'
data.table::data.table(jk_shape, pt_shape, boot_shape, norm_shape)%>%
  knitr::kable(align = "r", digits = 3, caption = cap4,
               col.names = c("Jackknife", "Percentile", "Bootstrap", "Normal"))
```
 
According to above quantities of confidence intervals, for the ratio of two Possion distribution expectations, CI of normal approximation with bootstrap method has best coverage, but it has largest confidence interval length.
